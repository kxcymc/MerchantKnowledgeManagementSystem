# ==================== 服务器配置 ====================
PORT=3002

# 跨域配置
ALLOW_ORIGINS=http://localhost:5173,http://localhost:3002

# ==================== LLM 模型配置 ====================
# 默认使用的模型提供商：volcano_ark (火山方舟引擎) | deepseek | qwen (千问)
# 注意：多模态功能（图片/语音）需要支持多模态的模型
# 推荐使用 qwen provider 配合多模态模型（如 qwen-vl-max, qwen3-vl-flash）
LLM_PROVIDER=volcano_ark

# 默认使用的模型名称/ID
# 火山方舟引擎（豆包）：doubao-seed-1-6-flash-250828（或 doubao-seed 系列其他模型）
#   可用的模型名称示例：
#   - doubao-seed-1-6-flash-250828（快速模型）
#   - doubao-seed-1-6-250828（标准模型）
#   更多模型请参考火山方舟控制台
#   注意：豆包模型可能不支持多模态，如需多模态功能请使用 qwen provider
# DeepSeek：deepseek-chat（固定值，无需修改）
#   注意：DeepSeek 可能不支持多模态，如需多模态功能请使用 qwen provider
# 千问（支持多模态）：
#   - qwen-turbo（文本模型）
#   - qwen-vl-max（多模态模型，支持图片）
#   - qwen3-vl-flash（多模态模型，支持图片，更快）
#   - qwen3-livetranslate-flash（多模态模型，支持图片和音频）
LLM_MODEL=doubao-seed-1-6-flash-250828

# 多模态模型推荐配置（如需使用多模态功能）：
# LLM_PROVIDER=qwen
# LLM_MODEL=qwen-vl-max
# 或
# LLM_MODEL=qwen3-vl-flash
# 或（支持图片+音频）
# LLM_MODEL=qwen3-livetranslate-flash

# LLM Base URL (可选，如果为空会根据 provider 自动选择)
# LLM_BASE_URL=

# LLM 温度参数
LLM_TEMPERATURE=0.7

# ==================== 火山方舟引擎 API 配置 ====================
# 火山方舟引擎 API Key
# 获取方式：
#   1. 登录火山方舟控制台：https://console.volcengine.com/ark
#   2. 进入"密钥管理" -> "API Key"
#   3. 创建或查看 API Key
#   4. 将 API Key 填写到下方（注意：不要泄露你的 API Key）
VOLCANO_ARK_API_KEY=your_volcano_ark_api_key_here

# 火山方舟引擎 Base URL（一般无需修改，除非使用其他区域）
# 默认：https://ark.cn-beijing.volces.com/api/v3
# 其他区域请参考火山方舟文档
VOLCANO_ARK_BASE_URL=https://ark.cn-beijing.volces.com/api/v3

# ==================== DeepSeek API 配置 ====================
# DeepSeek API Key
# 获取方式：
#   1. 登录 DeepSeek 平台：https://platform.deepseek.com
#   2. 进入"API Keys"页面：https://platform.deepseek.com/api_keys
#   3. 创建新的 API Key 或使用现有 Key
#   4. 将 API Key 填写到下方（注意：不要泄露你的 API Key）
DEEPSEEK_API_KEY=your_deepseek_api_key_here

# DeepSeek Base URL（一般无需修改）
# 默认：https://api.deepseek.com/v1
DEEPSEEK_BASE_URL=https://api.deepseek.com/v1

# ==================== DashScope API 配置 (千问) ====================
# DashScope API Key (用于文本嵌入和千问 LLM)
# 获取方式：
#   1. 登录阿里云 DashScope 控制台：https://dashscope.console.aliyun.com
#   2. 进入"API-KEY 管理"页面：https://dashscope.console.aliyun.com/apiKey
#   3. 创建新的 API Key
#   4. 将 API Key 填写到下方（注意：不要泄露你的 API Key）
DASHSCOPE_API_KEY=your_dashscope_api_key_here

# DashScope Base URL（一般无需修改）
# 默认：https://dashscope.aliyuncs.com/compatible-mode/v1
DASHSCOPE_BASE_URL=https://dashscope.aliyuncs.com/compatible-mode/v1

# ==================== 阿里云多模态API配置 ====================
# 图像理解API Key（用于图片理解功能）
# 获取方式：与 DashScope API Key 相同，使用同一个 Key 即可
# 注意：如果不设置，将自动使用 DASHSCOPE_API_KEY
# 图像理解功能需要开通通义千问VL模型服务（qwen-vl-max 或 qwen3-vl-flash）
ALI_IMAGE_API_KEY=your_ali_image_api_key_here

# 图像理解API URL（一般无需修改）
# 使用 MultiModalConversation API
# 默认：https://dashscope.aliyuncs.com/api/v1/services/aigc/multimodal-generation/generation
ALI_IMAGE_API_URL=https://dashscope.aliyuncs.com/api/v1/services/aigc/multimodal-generation/generation

# 语音识别API Key（用于语音转文字功能）
# 获取方式：与 DashScope API Key 相同，使用同一个 Key 即可
# 注意：如果不设置，将自动使用 DASHSCOPE_API_KEY
# 语音识别功能需要开通语音识别服务（paraformer-realtime-v2 或 fun-asr-realtime-2025-11-07）
ALI_SPEECH_API_KEY=your_ali_speech_api_key_here

# 语音识别API URL（一般无需修改）
# 使用 OpenAI 兼容模式 API
# 默认：https://dashscope.aliyuncs.com/compatible-mode/v1
# 注意：代码会自动转换为 /compatible-mode/v1/chat/completions 端点
ALI_SPEECH_API_URL=https://dashscope.aliyuncs.com/compatible-mode/v1

# ==================== Chroma 向量数据库配置 ====================
# 注意：QA Chatbot 只读取向量数据库，不进行任何写入操作
CHROMA_HOST=localhost
CHROMA_PORT=8000
CHROMA_COLLECTION_NAME=kb_documents

# ==================== MySQL 数据库配置 ====================
# QA Chatbot 业务数据库配置
# 说明：可以和 kb-backend 的 Knowledge 表共用同一个数据库（kb_database）
MYSQL_HOST=localhost
MYSQL_PORT=3306
MYSQL_USER=your_mysql_user
MYSQL_PASSWORD=your_mysql_password
MYSQL_DATABASE=kb_database

# 知识库数据库配置（用于检索 Knowledge 表）
# 如果和业务数据库是同一个数据库，可以只配置上面的 MYSQL_* 即可
# 如果需要连接不同的数据库或用户，可以单独配置下面的项
KBASE_DATABASE_HOST=localhost
KBASE_DATABASE_PORT=3306
KBASE_DATABASE_USER=KBase
KBASE_DATABASE_PASSWORD=your_kbase_password
KBASE_DATABASE_NAME=kb_database

# ==================== RAG 配置 ====================
RAG_TOP_K=5
RAG_MIN_SCORE=0.3
MAX_CONTEXT_TOKENS=4000

# ==================== Memory 配置 ====================
MEMORY_WINDOW_SIZE=6
MEMORY_SUMMARY_THRESHOLD=10

# ==================== 问题聚类配置 ====================
# 相似度阈值（0-1），用于判断问题是否属于同一类
# 值越高，只有非常相似的问题才会被归为一类
# 建议值：0.75（平衡聚类质量和数量）
CLUSTERING_SIMILARITY_THRESHOLD=0.75

# 最大检索聚类数量（用于相似度计算时的优化）
CLUSTERING_MAX_SIMILAR_CLUSTERS=10

# 是否启用问题聚类功能（true/false）
# 默认：true（启用）
CLUSTERING_ENABLED=true

